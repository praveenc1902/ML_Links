:::: Linear Regression(Lasso,Ridge) ::::

https://www.analyticsvidhya.com/blog/2021/06/linear-regression-in-machine-learning/

https://towardsdatascience.com/linear-regression-models-4a3d14b8d368
 
https://www.analyticsvidhya.com/blog/2016/01/ridge-lasso-regression-python-complete-tutorial/

https://www.datacamp.com/tutorial/tutorial-lasso-ridge-regression

--------------------------
HIGH LEVEL EXPLANATIO OF LASSO & RIDGE
--------------------------
--> Linear Regression is more biased, it gives more importance to features which will have more impact in the data
So, Linear Regression tends to over fit OR Under Fit 

Thats y 

We have to do some normalization to control the coefficents of features which are more influenced in forming the linear equation line 
for that, we use Lasso and Ridge Regression for normalizing which means, controlling the coefficents 

in Both Lasso & Ridge
we have a hyper parameter called Lambda(or alpha) which is used to control the coefficent 
**Please refer to the mathematical equation of Lasso nd Ridge**
The only difference b/w Lasso & Ridge is 
Ridge -- Square of coefficent * multiplied by lambda/alpha
Lasso -- no square of coeefeicent * multiplied by lambda/alpha

--> Lasso will sink the unwanted features coefficent to zero (it is diamond shaped)
--> Ridge will bring near to Zero but not exactly zero

When we have few features which are real impact to the linear regression then Lasso is the best 

Lasso Equation   --->   È(y-y`)**2+ alpha*È(m) 

Ridge Equation   --->   È(y-y`)**2+ alpha*È(m)**2






